{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import harmonic_conv\n",
    "import util\n",
    "import torch\n",
    "from torch.nn.modules.activation import PReLU, ReLU\n",
    "import torch.optim\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Harmonic_Net(nn.Module):\n",
    "    # HC: Harmonic Convolution\n",
    "    # RC: Regular Convolution\n",
    "    \"\"\"\n",
    "                                                                  [35-RC->out]\n",
    "    d0# [in->in in->35 ]                               [70->70 70->35]\n",
    "    d1#              d                                  u\n",
    "                    35-----------skip------------------>70\n",
    "                   [35->35 35->70 ]      [140->140 140->35]\n",
    "    d2#                         d          u   \n",
    "                               70-skip--->140     \n",
    "                              [70->70 70->70]\n",
    "                                       \n",
    "    <------------------------- HC ---------------------------->\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Step(a,b): #HC\n",
    "        [a->a b->b]\n",
    "\n",
    "    Down(a,b): # HC\n",
    "         ↓ down\n",
    "        [a->a a->b]\n",
    "                 \n",
    "    DownUp(a,b): # HC\n",
    "    down ↓       ↑ up\n",
    "        [a->a b->b]\n",
    "    \n",
    "    Up(a,b): # HC\n",
    "                 ↑ up\n",
    "        [a->a a->b]\n",
    "    \n",
    "    Last(a,b): #RC\n",
    "        [a-RC->b]\n",
    "    \"\"\"\n",
    "    def __init__(self,input_channel=1,kernel_size=3,conv_type=['HC']*5):\n",
    "        print(conv_type)\n",
    "        super().__init__()\n",
    "        self.step1 = Step(input_channel,35,kernel_size,conv_type[0])\n",
    "        self.step2 = Step(35,70, kernel_size,conv_type[1])\n",
    "        self.step3 = Step(70,70,kernel_size,conv_type[2])\n",
    "        self.step4 = Step(140,35, kernel_size,conv_type[3])\n",
    "        self.step5 = Step(70,35, kernel_size,conv_type[4])\n",
    "        self.last = Last(35,input_channel) # 1\n",
    "        self.down = Down()\n",
    "        self.up = Up()\n",
    "    def forward(self, x): # Batch, Channel, Freq.(=8*a), Time(=8*b)\n",
    "        x = self.step1(x)                   # 1,input,4a,4b -> 1,35,4a,4b\n",
    "        xd1 = self.down(x)                  # 1,35,4a,4b -> 1,35,2a,2b\n",
    "        x = self.step2(xd1)                 # 1,35,2a,2b -> 1,70,2a,2b\n",
    "        xd2 = self.down(x)                  # 1,70,2a,2b -> 1,70,a,b\n",
    "        x = self.step3(xd2)                 # 1,70,a,b -> 1,70,a,b\n",
    "        x = torch.cat((x,xd2),1)            # 1,70,a,b -> 1,140,a,b\n",
    "        x = self.up(x)                      # 1,140,a,b -> 1,140,2a,2b\n",
    "        x = self.step4(x)                   # 1,140,2a,2b -> 1,35,2a,2b\n",
    "        x = torch.cat((x,xd1),1)            # 1,35,2a,2b -> 1,70,2a,2b\n",
    "        x = self.up(x)                      # 1,70,2a,2b -> 1,70,4a,4b\n",
    "        x = self.step5(x)                   # 1,70,4a,4b -> 1,35,4a,4b\n",
    "        x = self.last(x)                    # 1,35,4a,4b -> 1,input,4a,4b\n",
    "\n",
    "        return x\n",
    "# HC base\n",
    "class Step(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, conv_type='HC'):\n",
    "        super().__init__()\n",
    "        time_pad = int((kernel_size-1)/2)\n",
    "        if conv_type=='HC':\n",
    "            self.step = nn.Sequential(\n",
    "                harmonic_conv.SingleHarmonicConv2d(in_channels, in_channels, kernel_size=kernel_size, anchor=kernel_size, padding=(0,time_pad), padding_mode='zeros'),\n",
    "                nn.InstanceNorm2d(in_channels),\n",
    "                nn.ReLU(),\n",
    "                harmonic_conv.SingleHarmonicConv2d(in_channels, out_channels, kernel_size=kernel_size, anchor=kernel_size, padding=(0,time_pad), padding_mode='zeros'),\n",
    "                nn.InstanceNorm2d(out_channels),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        elif conv_type=='RC':\n",
    "            self.step = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, padding=time_pad, padding_mode='zeros'),\n",
    "                nn.InstanceNorm2d(in_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=time_pad, padding_mode='zeros'),\n",
    "                nn.InstanceNorm2d(out_channels),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        self.step.apply(init_weights)\n",
    "    def forward(self, x):\n",
    "        return self.step(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.down = nn.Sequential(\n",
    "            nn.AvgPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        )\n",
    "        self.down.apply(init_weights)\n",
    "    def forward(self, x):\n",
    "        return self.down(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            nn.UpsamplingBilinear2d(scale_factor=(2,2))\n",
    "        )\n",
    "        self.up.apply(init_weights)\n",
    "    def forward(self, x):\n",
    "        return self.up(x)\n",
    "\n",
    "class Last(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        # time_pad = (kernel_size-1)/2\n",
    "        self.last = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        )\n",
    "        self.last.apply(init_weights)\n",
    "    def forward(self, x):\n",
    "        return self.last(x)\n",
    "\n",
    "\n",
    "class Skip(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
    "        super().__init__()\n",
    "        time_pad = int((kernel_size-1)/2)\n",
    "        self.step = nn.Sequential(\n",
    "            harmonic_conv.SingleHarmonicConv2d(in_channels, out_channels, kernel_size=kernel_size, anchor=kernel_size, padding=(0,time_pad), padding_mode='zeros'),\n",
    "            nn.InstanceNorm2d(in_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.step.apply(init_weights)\n",
    "    def forward(self, x):\n",
    "        return self.step(x)\n",
    "\n",
    "def init_weights(m):\n",
    "    torch.manual_seed(1)\n",
    "    if type(m) == nn.Conv2d:\n",
    "        nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "    if type(m) == harmonic_conv.SingleHarmonicConv2d:\n",
    "        nn.init.normal_(m.lowered_weight, mean=0, std=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def target_set(\n",
    "        self, \n",
    "        s_tn, \n",
    "        n_tn, \n",
    "        snr, \n",
    "        x_tn=None,\n",
    "        fftl=512,\n",
    "        shift=128\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        s: clean, n: noise, x: noisy\n",
    "        ~_t: time domain, ~_f: Time-Frequency domain, ~_A: Time-Frequency domain (Amplitude)\n",
    "        ~_~n: numpy, ~_~t: tensor\n",
    "        \"\"\"\n",
    "        if type(s_tn) is str: self.s_tn,_,_ = util.wavread(s_tn)\n",
    "        else: self.s_tn = s_tn\n",
    "        if type(n_tn) is str: self.n_tn,_,_ = util.wavread(n_tn)\n",
    "        else: self.n_tn = n_tn\n",
    "        if x_tn is None: \n",
    "            self.x_tn, self.n_tn = util.create_mixture(self.s_tn, self.n_tn, snr)\n",
    "        else: self.x_tn = x_tn\n",
    "\n",
    "        self.x_fn = util.stft(self.x_tn, fftl=fftl, shift=shift)\n",
    "        self.x_An = np.abs(self.x_fn)\n",
    "        self.x_An[self.x_An==0] = np.spacing(1)\n",
    "\n",
    "        self.fftl = fftl\n",
    "        self.shift = shift\n",
    "\n",
    "    def get_s(\n",
    "        self,\n",
    "        domain='time',\n",
    "        fftl=None,\n",
    "        shift=None\n",
    "    ) -> np.ndarray:\n",
    "        if domain == 'time':\n",
    "            return self.s_tn\n",
    "        if domain == 'freq':\n",
    "            if fftl is None:\n",
    "                fftl = self.fftl\n",
    "            if shift is None:\n",
    "                shift = self.shift\n",
    "            return util.stft(self.s_tn, fftl=fftl, shift=shift)\n",
    "        else:\n",
    "            assert(False), f\"domain must be 'time' or 'freq'.\"\n",
    "    \n",
    "    def get_n(\n",
    "        self,\n",
    "        domain='time',\n",
    "        fftl=512,\n",
    "        shift=128\n",
    "    ) -> np.ndarray:\n",
    "        if domain == 'time':\n",
    "            return self.n_tn\n",
    "        if domain == 'freq':\n",
    "            return util.stft(self.n_tn, fftl=fftl, shift=shift)\n",
    "        else:\n",
    "            assert(False), f\"domain must be 'time' or 'freq'.\"\n",
    "    \n",
    "    def train_setting(\n",
    "        self,\n",
    "        device='cuda:0',\n",
    "        isrelu=False,\n",
    "        input_channel=1,\n",
    "        lr = 0.05,\n",
    "        kernel_size=3,\n",
    "        conv_type=['HC']*7\n",
    "    ) -> None:\n",
    "        torch.manual_seed(1234)\n",
    "        self.model = Harmonic_Net(input_channel=input_channel, kernel_size=kernel_size, conv_type=conv_type).to(device)\n",
    "        self.device = device\n",
    "\n",
    "        params = []\n",
    "        params += [x for x in self.model.parameters()]\n",
    "        self.optimizer = torch.optim.Adam(params, lr=lr)\n",
    "    \n",
    "    def Loss(self, x1,x2,p=2.0):\n",
    "        lp_loss = torch.sum( torch.pow( torch.abs(x1-x2)+1.0e-6,p) )\n",
    "        return lp_loss\n",
    "    \n",
    "    def train_xy(\n",
    "        self,\n",
    "        iter,\n",
    "        sum_iter,\n",
    "        loss_p = 1\n",
    "    ):\n",
    "        if sum_iter == 0: # 学習の初めの前処理\n",
    "            self.x_realn = np.real(self.x_fn)\n",
    "            self.x_realt = util.np_to_torch(self.x_realn).float().to(self.device) # [time, freq]\n",
    "            self.x_realt = torch.unsqueeze( torch.unsqueeze(self.x_realt, 0),0 ) # [batch=1, channel=1, time, freq]\n",
    "            self.x_cpxn = np.imag(self.x_fn)\n",
    "            self.x_cpxt = util.np_to_torch(self.x_cpxn).float().to(self.device) # [time, freq]\n",
    "            self.x_cpxt = torch.unsqueeze( torch.unsqueeze(self.x_cpxt, 0),0 ) # [batch=1, channel=1, time, freq]\n",
    "            self.x_target = torch.cat((self.x_realt, self.x_cpxt),1)\n",
    "            self.x_target, self.pad1, self.pad2 = util.pad32(self.x_target) # [1,1, time+pad1, freq+pad2]\n",
    "            self.x_target = self.x_target[:,:,:,self.pad2:] # [1,1,time+pad1,freq] HCではfreq binを変えてはいけない\n",
    "            self.pad2 = 0\n",
    "            self.x_target = self.x_target.permute(0,1,3,2) # [1,1,freq,time+pad1]\n",
    "            self.x_target_cut = self.x_target[:,:,1:,:] # Frequencyの直流成分をカット\n",
    "            self.net_input = torch.rand(size=self.x_target_cut.shape).float().to(self.device) * 0.1\n",
    "\n",
    "        # 学習\n",
    "        for i in range(iter+1):\n",
    "            sum_iter += 1\n",
    "            print('\\r%d回目' %(sum_iter), end='')\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            out_2c = self.model(self.net_input)\n",
    "            loss_num = self.Loss(out_2c, self.x_target_cut, loss_p)\n",
    "            loss_num.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "        # 後処理\n",
    "        sum_iter -= 1\n",
    "        out_2c = torch.cat((torch.unsqueeze(self.x_target[:,:,0,:],2),out_2c),2)\n",
    "        out_2c = out_2c.permute(1,0,3,2) # [1,1,time+pad1,freq]\n",
    "        out_2c = util.torch_to_np(out_2c) # [1,1,time+pad1,freq]\n",
    "        out_2c = out_2c[:,:,self.pad1:,self.pad2:] # [time,freq]\n",
    "        out_fn = out_2c[0,0]+1j*out_2c[1,0]\n",
    "        out_tn = util.istft(np.abs(out_fn)*np.exp(1j*np.angle(out_fn)), x_len=len(self.x_tn), fftl=self.fftl, shift = self.shift)\n",
    "        return out_tn, sum_iter, loss_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dp = Train()\n",
    "\n",
    "s_tn,sr,subtype = util.wavread('LJ037-0171.wav') # LJspeech -> https://keithito.com/LJ-Speech-Dataset/\n",
    "noise = np.random.normal(0.0,0.1,size=len(s_tn))\n",
    "dp.target_set(\n",
    "    s_tn=s_tn,\n",
    "    n_tn=noise,\n",
    "    snr=10,\n",
    "    fftl=1024,\n",
    "    shift=64\n",
    ")\n",
    "\n",
    "dp.train_setting(\n",
    "    input_channel=2,\n",
    "    lr=0.001,\n",
    "    kernel_size=3 # Note: the original paper's kernel_size and anchor is 7. (the parameter kernelsize=3, anchor=3 now)\n",
    ")\n",
    "sdr_ = round(util.sisdr(dp.get_s(), dp.x_tn),4)\n",
    "util.specshow(dp.x_tn, title=f'Noisy\\nsi-sdr: {sdr_}',sr=sr,fftl=1024,shift=64)\n",
    "\n",
    "sum_iter = 0\n",
    "for i in [1,10,100,1000,2000,5000,10000]:\n",
    "    iter = i-sum_iter\n",
    "    out_tn,sum_iter,_ = dp.train_xy(iter, sum_iter, loss_p=2)\n",
    "    sdr_ = round(util.sisdr(dp.get_s(), out_tn),4)\n",
    "    util.specshow(out_tn, title=f'{sum_iter}\\nsi-sdr: {sdr_}',fftl=dp.fftl,shift=dp.shift)\n",
    "    util.wavwrite(f'.wav/{i}.wav', out_tn, sr, subtype)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
